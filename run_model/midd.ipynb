{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhhaibo2023/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(os.path.join(project_root, 'code'))\n",
    "\n",
    "from model.dataset import MIDD\n",
    "from model.run_train import run\n",
    "import model.config as config\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score, classification_report\n",
    "from transformers import AutoTokenizer\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import time\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2025\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:1'\n",
    "\n",
    "# 加载数据\n",
    "r_data = torch.load('../data/midd.pt')\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.ptm)  # 使用BERT中文分词器\n",
    "\n",
    "dataset_name = 'midd'\n",
    "dataset = MIDD(\n",
    "    dataset_name = dataset_name,\n",
    "    response_texts=r_data['responses'],\n",
    "    labels=r_data['labels'],\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=64\n",
    ")\n",
    "print(len(dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhhaibo2023/program/msce/code/run_model/midd\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-5\n",
    "Weight_Decay = 1e-4\n",
    "EPOCHS = 50\n",
    "BS = 32\n",
    "Dropout = 0.5\n",
    "\n",
    "\n",
    "gammas = [1.0, 0.7072, 0.2005]\n",
    "\n",
    "\n",
    "classify_flag ='bin' # penta\n",
    "\n",
    "logdir_root = os.path.join(os.getcwd(), dataset_name)\n",
    "print(logdir_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_model_path: /home/zhhaibo2023/Pretrained_Model/bert-base-chinese\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DepressionDetectionModel\n",
      "num_stimuls:  9\n",
      "fold: 1, epoch: 1, train_loss: 3.1093, train_acc: 54.33, train_fscore: 67.35, test_loss: 2.3679, test_acc: 72.12, test_fscore: 80.0, time: 9.2 sec\n",
      "fold: 1, epoch: 2, train_loss: 2.2887, train_acc: 55.29, train_fscore: 66.06, test_loss: 1.7911, test_acc: 59.62, test_fscore: 74.7, time: 7.55 sec\n",
      "fold: 1, epoch: 3, train_loss: 1.9026, train_acc: 64.42, train_fscore: 73.38, test_loss: 1.6077, test_acc: 82.69, test_fscore: 86.96, time: 7.62 sec\n",
      "fold: 1, epoch: 4, train_loss: 1.7443, train_acc: 69.23, train_fscore: 76.73, test_loss: 1.5796, test_acc: 65.38, test_fscore: 62.5, time: 7.58 sec\n",
      "fold: 1, epoch: 5, train_loss: 1.6154, train_acc: 78.12, train_fscore: 81.91, test_loss: 1.3568, test_acc: 88.46, test_fscore: 90.32, time: 7.85 sec\n",
      "fold: 1, epoch: 6, train_loss: 1.5046, train_acc: 83.89, train_fscore: 86.13, test_loss: 1.2874, test_acc: 86.54, test_fscore: 88.52, time: 7.46 sec\n",
      "fold: 1, epoch: 7, train_loss: 1.4536, train_acc: 82.21, train_fscore: 83.91, test_loss: 1.264, test_acc: 85.58, test_fscore: 87.6, time: 7.49 sec\n",
      "fold: 1, epoch: 8, train_loss: 1.398, train_acc: 85.34, train_fscore: 87.53, test_loss: 1.2284, test_acc: 88.46, test_fscore: 90.32, time: 7.56 sec\n",
      "fold: 1, epoch: 9, train_loss: 1.311, train_acc: 89.18, train_fscore: 90.64, test_loss: 1.1942, test_acc: 88.46, test_fscore: 90.62, time: 7.63 sec\n",
      "fold: 1, epoch: 10, train_loss: 1.2229, train_acc: 92.55, train_fscore: 93.56, test_loss: 1.2663, test_acc: 81.73, test_fscore: 84.3, time: 7.58 sec\n",
      "fold: 1, epoch: 11, train_loss: 1.1597, train_acc: 96.15, train_fscore: 96.58, test_loss: 1.208, test_acc: 88.46, test_fscore: 90.77, time: 7.54 sec\n",
      "fold: 1, epoch: 12, train_loss: 1.1008, train_acc: 97.36, train_fscore: 97.67, test_loss: 1.4208, test_acc: 81.73, test_fscore: 83.76, time: 7.52 sec\n",
      "fold: 1, epoch: 13, train_loss: 1.0512, train_acc: 99.28, train_fscore: 99.36, test_loss: 1.4063, test_acc: 79.81, test_fscore: 82.64, time: 7.51 sec\n",
      "fold: 1, epoch: 14, train_loss: 1.0189, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.377, test_acc: 81.73, test_fscore: 84.55, time: 7.52 sec\n",
      "fold: 1, epoch: 15, train_loss: 1.0039, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.3264, test_acc: 84.62, test_fscore: 87.3, time: 7.58 sec\n",
      "fold: 1, epoch: 16, train_loss: 0.9984, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4765, test_acc: 82.69, test_fscore: 85.0, time: 7.51 sec\n",
      "fold: 1, epoch: 17, train_loss: 0.9905, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.5615, test_acc: 82.69, test_fscore: 84.48, time: 7.55 sec\n",
      "fold: 1, epoch: 18, train_loss: 0.9903, train_acc: 99.76, train_fscore: 99.79, test_loss: 1.7409, test_acc: 80.77, test_fscore: 82.46, time: 7.55 sec\n",
      "fold: 1, epoch: 19, train_loss: 0.9825, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.6865, test_acc: 79.81, test_fscore: 82.05, time: 7.53 sec\n",
      "fold: 1, epoch: 20, train_loss: 0.9768, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7237, test_acc: 78.85, test_fscore: 80.7, time: 7.47 sec\n",
      "fold: 1, epoch: 21, train_loss: 0.9722, train_acc: 99.76, train_fscore: 99.79, test_loss: 1.6324, test_acc: 80.77, test_fscore: 82.76, time: 7.47 sec\n",
      "fold: 1, epoch: 22, train_loss: 0.9715, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.5299, test_acc: 82.69, test_fscore: 85.25, time: 7.46 sec\n",
      "fold: 1, epoch: 23, train_loss: 0.9696, train_acc: 99.76, train_fscore: 99.79, test_loss: 1.4604, test_acc: 84.62, test_fscore: 87.5, time: 7.51 sec\n",
      "fold: 1, epoch: 24, train_loss: 0.9786, train_acc: 99.52, train_fscore: 99.57, test_loss: 1.4902, test_acc: 84.62, test_fscore: 87.3, time: 7.57 sec\n",
      "fold: 1, epoch: 25, train_loss: 0.9797, train_acc: 99.52, train_fscore: 99.57, test_loss: 1.6541, test_acc: 80.77, test_fscore: 83.33, time: 7.53 sec\n",
      "fold: 1, epoch: 26, train_loss: 0.9713, train_acc: 99.76, train_fscore: 99.79, test_loss: 1.4143, test_acc: 88.46, test_fscore: 90.91, time: 7.58 sec\n",
      "fold: 1, epoch: 27, train_loss: 0.9622, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.5776, test_acc: 81.73, test_fscore: 84.3, time: 7.58 sec\n",
      "fold: 1, epoch: 28, train_loss: 0.9559, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.8023, test_acc: 76.92, test_fscore: 78.95, time: 7.55 sec\n",
      "fold: 1, epoch: 29, train_loss: 0.9526, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4675, test_acc: 84.62, test_fscore: 87.5, time: 7.52 sec\n",
      "fold: 1, epoch: 30, train_loss: 0.9496, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.5394, test_acc: 84.62, test_fscore: 86.89, time: 7.51 sec\n",
      "fold: 1, epoch: 31, train_loss: 0.9476, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.448, test_acc: 85.58, test_fscore: 88.0, time: 7.48 sec\n",
      "fold: 1, epoch: 32, train_loss: 0.9458, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4722, test_acc: 86.54, test_fscore: 88.71, time: 7.57 sec\n",
      "fold: 1, epoch: 33, train_loss: 0.9441, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4728, test_acc: 86.54, test_fscore: 88.71, time: 7.57 sec\n",
      "fold: 1, epoch: 34, train_loss: 0.9429, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4506, test_acc: 85.58, test_fscore: 88.0, time: 7.51 sec\n",
      "fold: 1, epoch: 35, train_loss: 0.942, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4968, test_acc: 85.58, test_fscore: 87.8, time: 7.56 sec\n",
      "fold: 1, epoch: 36, train_loss: 0.9404, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4859, test_acc: 86.54, test_fscore: 88.71, time: 7.58 sec\n",
      "fold: 1, epoch: 37, train_loss: 0.9397, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4551, test_acc: 86.54, test_fscore: 88.71, time: 7.8 sec\n",
      "fold: 1, epoch: 38, train_loss: 0.9387, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4851, test_acc: 86.54, test_fscore: 88.71, time: 7.54 sec\n",
      "fold: 1, epoch: 39, train_loss: 0.9376, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.49, test_acc: 86.54, test_fscore: 88.71, time: 7.56 sec\n",
      "fold: 1, epoch: 40, train_loss: 0.937, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.472, test_acc: 86.54, test_fscore: 88.71, time: 7.58 sec\n",
      "fold: 1, epoch: 41, train_loss: 0.9362, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4593, test_acc: 86.54, test_fscore: 88.71, time: 7.54 sec\n",
      "fold: 1, epoch: 42, train_loss: 0.9353, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4651, test_acc: 86.54, test_fscore: 88.71, time: 7.52 sec\n",
      "fold: 1, epoch: 43, train_loss: 0.9344, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4879, test_acc: 86.54, test_fscore: 88.71, time: 7.57 sec\n",
      "fold: 1, epoch: 44, train_loss: 0.934, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4822, test_acc: 86.54, test_fscore: 88.71, time: 7.52 sec\n",
      "fold: 1, epoch: 45, train_loss: 0.9333, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4682, test_acc: 86.54, test_fscore: 88.71, time: 7.47 sec\n",
      "fold: 1, epoch: 46, train_loss: 0.9325, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.52, test_acc: 84.62, test_fscore: 86.89, time: 7.61 sec\n",
      "fold: 1, epoch: 47, train_loss: 0.932, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.478, test_acc: 86.54, test_fscore: 88.71, time: 7.51 sec\n",
      "fold: 1, epoch: 48, train_loss: 0.9317, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4607, test_acc: 85.58, test_fscore: 88.0, time: 7.53 sec\n",
      "fold: 1, epoch: 49, train_loss: 0.9311, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.5475, test_acc: 84.62, test_fscore: 86.89, time: 7.6 sec\n",
      "fold: 1, epoch: 50, train_loss: 0.9304, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.4934, test_acc: 86.54, test_fscore: 88.71, time: 7.58 sec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.8571    0.8571        42\n",
      "           1     0.9032    0.9032    0.9032        62\n",
      "\n",
      "    accuracy                         0.8846       104\n",
      "   macro avg     0.8802    0.8802    0.8802       104\n",
      "weighted avg     0.8846    0.8846    0.8846       104\n",
      "\n",
      "[[36  6]\n",
      " [ 6 56]]\n",
      "best model saved in:  /home/zhhaibo2023/program/msce/code/run_model/midd_runs/01-20_22-43_midd_bin_lr1e-05_dropout0.5_bs32_epochs50_fold1/saved_model/midd_model_fold1_acc.pt\n",
      "Test performance..\n",
      "fold: 1, F-Score: 90.91\n",
      "fold: 1, F-Score-index: 26\n",
      "fold: 1, Acc: 88.46\n",
      "fold: 1, Acc-index: 5\n",
      "bert_model_path: /home/zhhaibo2023/Pretrained_Model/bert-base-chinese\n",
      "Model: DepressionDetectionModel\n",
      "num_stimuls:  9\n",
      "fold: 2, epoch: 1, train_loss: 3.1831, train_acc: 59.38, train_fscore: 72.61, test_loss: 2.55, test_acc: 51.92, test_fscore: 68.35, time: 7.9 sec\n",
      "fold: 2, epoch: 2, train_loss: 2.4122, train_acc: 59.86, train_fscore: 72.58, test_loss: 1.9924, test_acc: 67.31, test_fscore: 66.67, time: 7.6 sec\n",
      "fold: 2, epoch: 3, train_loss: 1.9875, train_acc: 64.42, train_fscore: 76.13, test_loss: 1.7218, test_acc: 78.85, test_fscore: 81.97, time: 7.58 sec\n",
      "fold: 2, epoch: 4, train_loss: 1.7883, train_acc: 68.51, train_fscore: 74.56, test_loss: 1.558, test_acc: 75.0, test_fscore: 79.69, time: 7.74 sec\n",
      "fold: 2, epoch: 5, train_loss: 1.6158, train_acc: 81.25, train_fscore: 84.52, test_loss: 1.5254, test_acc: 75.96, test_fscore: 80.31, time: 7.54 sec\n",
      "fold: 2, epoch: 6, train_loss: 1.5366, train_acc: 80.05, train_fscore: 83.5, test_loss: 1.4904, test_acc: 75.96, test_fscore: 80.31, time: 7.54 sec\n",
      "fold: 2, epoch: 7, train_loss: 1.4692, train_acc: 82.21, train_fscore: 85.43, test_loss: 1.4221, test_acc: 79.81, test_fscore: 82.05, time: 7.66 sec\n",
      "fold: 2, epoch: 8, train_loss: 1.3803, train_acc: 86.78, train_fscore: 89.11, test_loss: 1.4219, test_acc: 80.77, test_fscore: 82.14, time: 7.63 sec\n",
      "fold: 2, epoch: 9, train_loss: 1.3142, train_acc: 90.62, train_fscore: 92.12, test_loss: 1.423, test_acc: 80.77, test_fscore: 82.14, time: 7.52 sec\n",
      "fold: 2, epoch: 10, train_loss: 1.2587, train_acc: 91.59, train_fscore: 92.93, test_loss: 1.5229, test_acc: 77.88, test_fscore: 78.1, time: 7.54 sec\n",
      "fold: 2, epoch: 11, train_loss: 1.2278, train_acc: 93.51, train_fscore: 94.52, test_loss: 1.4701, test_acc: 80.77, test_fscore: 82.14, time: 7.52 sec\n",
      "fold: 2, epoch: 12, train_loss: 1.1901, train_acc: 94.47, train_fscore: 95.28, test_loss: 1.5099, test_acc: 80.77, test_fscore: 82.46, time: 7.61 sec\n",
      "fold: 2, epoch: 13, train_loss: 1.1242, train_acc: 96.63, train_fscore: 97.14, test_loss: 1.61, test_acc: 77.88, test_fscore: 78.5, time: 7.53 sec\n",
      "fold: 2, epoch: 14, train_loss: 1.0774, train_acc: 98.8, train_fscore: 98.97, test_loss: 1.598, test_acc: 79.81, test_fscore: 81.08, time: 7.6 sec\n",
      "fold: 2, epoch: 15, train_loss: 1.0439, train_acc: 99.28, train_fscore: 99.38, test_loss: 1.6705, test_acc: 79.81, test_fscore: 81.08, time: 7.47 sec\n",
      "fold: 2, epoch: 16, train_loss: 1.0191, train_acc: 99.76, train_fscore: 99.79, test_loss: 1.6868, test_acc: 79.81, test_fscore: 81.08, time: 7.51 sec\n",
      "fold: 2, epoch: 17, train_loss: 1.0117, train_acc: 99.28, train_fscore: 99.38, test_loss: 1.6914, test_acc: 79.81, test_fscore: 81.42, time: 7.54 sec\n",
      "fold: 2, epoch: 18, train_loss: 1.0003, train_acc: 99.52, train_fscore: 99.59, test_loss: 1.6998, test_acc: 80.77, test_fscore: 82.46, time: 7.52 sec\n",
      "fold: 2, epoch: 19, train_loss: 0.9879, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7347, test_acc: 81.73, test_fscore: 83.19, time: 7.59 sec\n",
      "fold: 2, epoch: 20, train_loss: 0.9814, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7681, test_acc: 79.81, test_fscore: 81.74, time: 7.53 sec\n",
      "fold: 2, epoch: 21, train_loss: 0.9779, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.8064, test_acc: 79.81, test_fscore: 82.35, time: 7.58 sec\n",
      "fold: 2, epoch: 22, train_loss: 0.9726, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7831, test_acc: 82.69, test_fscore: 84.21, time: 7.62 sec\n",
      "fold: 2, epoch: 23, train_loss: 0.9695, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7906, test_acc: 82.69, test_fscore: 84.21, time: 7.77 sec\n",
      "fold: 2, epoch: 24, train_loss: 0.9658, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.8055, test_acc: 80.77, test_fscore: 81.82, time: 7.57 sec\n",
      "fold: 2, epoch: 25, train_loss: 0.9623, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9275, test_acc: 79.81, test_fscore: 82.35, time: 7.57 sec\n",
      "fold: 2, epoch: 26, train_loss: 0.9596, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.8298, test_acc: 78.85, test_fscore: 80.7, time: 7.61 sec\n",
      "fold: 2, epoch: 27, train_loss: 0.9571, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9183, test_acc: 79.81, test_fscore: 82.35, time: 7.71 sec\n",
      "fold: 2, epoch: 28, train_loss: 0.9561, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9848, test_acc: 79.81, test_fscore: 82.35, time: 7.61 sec\n",
      "fold: 2, epoch: 29, train_loss: 0.954, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.8752, test_acc: 79.81, test_fscore: 81.74, time: 7.51 sec\n",
      "fold: 2, epoch: 30, train_loss: 0.9508, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9344, test_acc: 79.81, test_fscore: 82.05, time: 7.65 sec\n",
      "fold: 2, epoch: 31, train_loss: 0.9503, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9581, test_acc: 80.77, test_fscore: 82.76, time: 7.6 sec\n",
      "fold: 2, epoch: 32, train_loss: 0.948, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.8874, test_acc: 80.77, test_fscore: 82.76, time: 7.49 sec\n",
      "fold: 2, epoch: 33, train_loss: 0.9468, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9157, test_acc: 80.77, test_fscore: 82.76, time: 7.62 sec\n",
      "fold: 2, epoch: 34, train_loss: 0.9451, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9644, test_acc: 78.85, test_fscore: 81.36, time: 7.5 sec\n",
      "fold: 2, epoch: 35, train_loss: 0.9442, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9322, test_acc: 80.77, test_fscore: 82.76, time: 7.65 sec\n",
      "fold: 2, epoch: 36, train_loss: 0.9426, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9406, test_acc: 80.77, test_fscore: 82.76, time: 7.68 sec\n",
      "fold: 2, epoch: 37, train_loss: 0.9415, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9297, test_acc: 78.85, test_fscore: 81.03, time: 7.63 sec\n",
      "fold: 2, epoch: 38, train_loss: 0.9405, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9714, test_acc: 78.85, test_fscore: 81.36, time: 7.67 sec\n",
      "fold: 2, epoch: 39, train_loss: 0.9397, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9827, test_acc: 78.85, test_fscore: 81.36, time: 7.5 sec\n",
      "fold: 2, epoch: 40, train_loss: 0.9388, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.968, test_acc: 79.81, test_fscore: 81.74, time: 7.66 sec\n",
      "fold: 2, epoch: 41, train_loss: 0.9378, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0066, test_acc: 78.85, test_fscore: 81.36, time: 7.54 sec\n",
      "fold: 2, epoch: 42, train_loss: 0.9369, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0408, test_acc: 78.85, test_fscore: 81.36, time: 7.63 sec\n",
      "fold: 2, epoch: 43, train_loss: 0.9359, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9927, test_acc: 79.81, test_fscore: 82.05, time: 7.61 sec\n",
      "fold: 2, epoch: 44, train_loss: 0.9351, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0163, test_acc: 78.85, test_fscore: 81.36, time: 7.71 sec\n",
      "fold: 2, epoch: 45, train_loss: 0.9347, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.004, test_acc: 80.77, test_fscore: 82.76, time: 7.58 sec\n",
      "fold: 2, epoch: 46, train_loss: 0.934, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.001, test_acc: 79.81, test_fscore: 81.74, time: 7.68 sec\n",
      "fold: 2, epoch: 47, train_loss: 0.9335, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0916, test_acc: 78.85, test_fscore: 81.36, time: 7.69 sec\n",
      "fold: 2, epoch: 48, train_loss: 0.9329, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0604, test_acc: 78.85, test_fscore: 81.36, time: 7.69 sec\n",
      "fold: 2, epoch: 49, train_loss: 0.9318, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0416, test_acc: 79.81, test_fscore: 82.05, time: 7.58 sec\n",
      "fold: 2, epoch: 50, train_loss: 0.9314, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0658, test_acc: 78.85, test_fscore: 81.36, time: 7.49 sec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8636    0.7600    0.8085        50\n",
      "           1     0.8000    0.8889    0.8421        54\n",
      "\n",
      "    accuracy                         0.8269       104\n",
      "   macro avg     0.8318    0.8244    0.8253       104\n",
      "weighted avg     0.8306    0.8269    0.8260       104\n",
      "\n",
      "[[38 12]\n",
      " [ 6 48]]\n",
      "best model saved in:  /home/zhhaibo2023/program/msce/code/run_model/midd_runs/01-20_22-49_midd_bin_lr1e-05_dropout0.5_bs32_epochs50_fold2/saved_model/midd_model_fold2_acc.pt\n",
      "Test performance..\n",
      "fold: 2, F-Score: 84.21\n",
      "fold: 2, F-Score-index: 22\n",
      "fold: 2, Acc: 82.69\n",
      "fold: 2, Acc-index: 22\n",
      "bert_model_path: /home/zhhaibo2023/Pretrained_Model/bert-base-chinese\n",
      "Model: DepressionDetectionModel\n",
      "num_stimuls:  9\n",
      "fold: 3, epoch: 1, train_loss: 3.2878, train_acc: 51.92, train_fscore: 65.28, test_loss: 2.514, test_acc: 61.54, test_fscore: 76.19, time: 8.02 sec\n",
      "fold: 3, epoch: 2, train_loss: 2.4057, train_acc: 61.06, train_fscore: 73.09, test_loss: 1.8534, test_acc: 68.27, test_fscore: 79.25, time: 7.75 sec\n",
      "fold: 3, epoch: 3, train_loss: 1.922, train_acc: 68.27, train_fscore: 75.37, test_loss: 1.5694, test_acc: 77.88, test_fscore: 83.45, time: 7.62 sec\n",
      "fold: 3, epoch: 4, train_loss: 1.6977, train_acc: 75.96, train_fscore: 80.16, test_loss: 1.4293, test_acc: 79.81, test_fscore: 83.97, time: 7.74 sec\n",
      "fold: 3, epoch: 5, train_loss: 1.5538, train_acc: 83.89, train_fscore: 86.52, test_loss: 1.3712, test_acc: 81.73, test_fscore: 85.93, time: 7.66 sec\n",
      "fold: 3, epoch: 6, train_loss: 1.4616, train_acc: 84.38, train_fscore: 86.32, test_loss: 1.4369, test_acc: 81.73, test_fscore: 86.33, time: 7.48 sec\n",
      "fold: 3, epoch: 7, train_loss: 1.3968, train_acc: 86.54, train_fscore: 88.66, test_loss: 1.3948, test_acc: 81.73, test_fscore: 85.27, time: 7.55 sec\n",
      "fold: 3, epoch: 8, train_loss: 1.3064, train_acc: 91.35, train_fscore: 92.56, test_loss: 1.4183, test_acc: 83.65, test_fscore: 86.82, time: 7.75 sec\n",
      "fold: 3, epoch: 9, train_loss: 1.221, train_acc: 93.99, train_fscore: 94.71, test_loss: 1.4734, test_acc: 80.77, test_fscore: 84.85, time: 7.59 sec\n",
      "fold: 3, epoch: 10, train_loss: 1.1873, train_acc: 94.47, train_fscore: 95.12, test_loss: 1.519, test_acc: 83.65, test_fscore: 86.61, time: 7.51 sec\n",
      "fold: 3, epoch: 11, train_loss: 1.1453, train_acc: 96.88, train_fscore: 97.24, test_loss: 1.5259, test_acc: 85.58, test_fscore: 88.37, time: 7.71 sec\n",
      "fold: 3, epoch: 12, train_loss: 1.0815, train_acc: 98.56, train_fscore: 98.72, test_loss: 1.591, test_acc: 83.65, test_fscore: 87.22, time: 7.75 sec\n",
      "fold: 3, epoch: 13, train_loss: 1.0609, train_acc: 98.32, train_fscore: 98.51, test_loss: 1.6229, test_acc: 79.81, test_fscore: 83.2, time: 7.64 sec\n",
      "fold: 3, epoch: 14, train_loss: 1.0172, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.6574, test_acc: 83.65, test_fscore: 86.61, time: 7.61 sec\n",
      "fold: 3, epoch: 15, train_loss: 1.0032, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.6569, test_acc: 82.69, test_fscore: 85.71, time: 7.56 sec\n",
      "fold: 3, epoch: 16, train_loss: 0.9939, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.6874, test_acc: 79.81, test_fscore: 82.93, time: 7.67 sec\n",
      "fold: 3, epoch: 17, train_loss: 0.9857, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7051, test_acc: 83.65, test_fscore: 87.22, time: 7.76 sec\n",
      "fold: 3, epoch: 18, train_loss: 0.9792, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7041, test_acc: 80.77, test_fscore: 84.62, time: 7.63 sec\n",
      "fold: 3, epoch: 19, train_loss: 0.9758, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7121, test_acc: 80.77, test_fscore: 84.62, time: 7.64 sec\n",
      "fold: 3, epoch: 20, train_loss: 0.9727, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7764, test_acc: 79.81, test_fscore: 82.64, time: 7.7 sec\n",
      "fold: 3, epoch: 21, train_loss: 0.9669, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.726, test_acc: 80.77, test_fscore: 84.62, time: 7.64 sec\n",
      "fold: 3, epoch: 22, train_loss: 0.9631, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7261, test_acc: 81.73, test_fscore: 85.5, time: 7.56 sec\n",
      "fold: 3, epoch: 23, train_loss: 0.96, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7276, test_acc: 82.69, test_fscore: 86.36, time: 7.55 sec\n",
      "fold: 3, epoch: 24, train_loss: 0.9574, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7439, test_acc: 82.69, test_fscore: 86.36, time: 7.59 sec\n",
      "fold: 3, epoch: 25, train_loss: 0.9548, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7419, test_acc: 79.81, test_fscore: 82.93, time: 7.48 sec\n",
      "fold: 3, epoch: 26, train_loss: 0.9543, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7741, test_acc: 79.81, test_fscore: 82.64, time: 7.5 sec\n",
      "fold: 3, epoch: 27, train_loss: 0.9522, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7864, test_acc: 77.88, test_fscore: 81.6, time: 7.6 sec\n",
      "fold: 3, epoch: 28, train_loss: 0.9496, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7847, test_acc: 83.65, test_fscore: 87.02, time: 7.51 sec\n",
      "fold: 3, epoch: 29, train_loss: 0.9472, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7858, test_acc: 84.62, test_fscore: 87.88, time: 7.52 sec\n",
      "fold: 3, epoch: 30, train_loss: 0.9463, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7518, test_acc: 79.81, test_fscore: 83.46, time: 7.61 sec\n",
      "fold: 3, epoch: 31, train_loss: 0.9447, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7686, test_acc: 83.65, test_fscore: 87.02, time: 7.51 sec\n",
      "fold: 3, epoch: 32, train_loss: 0.9426, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.771, test_acc: 83.65, test_fscore: 87.02, time: 7.59 sec\n",
      "fold: 3, epoch: 33, train_loss: 0.9413, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7788, test_acc: 83.65, test_fscore: 87.02, time: 7.57 sec\n",
      "fold: 3, epoch: 34, train_loss: 0.9398, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7569, test_acc: 81.73, test_fscore: 85.27, time: 7.53 sec\n",
      "fold: 3, epoch: 35, train_loss: 0.9391, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7644, test_acc: 79.81, test_fscore: 83.46, time: 7.51 sec\n",
      "fold: 3, epoch: 36, train_loss: 0.9385, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.8127, test_acc: 84.62, test_fscore: 87.88, time: 7.51 sec\n",
      "fold: 3, epoch: 37, train_loss: 0.9371, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.8027, test_acc: 83.65, test_fscore: 87.02, time: 7.5 sec\n",
      "fold: 3, epoch: 38, train_loss: 0.9363, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7702, test_acc: 80.77, test_fscore: 84.38, time: 7.59 sec\n",
      "fold: 3, epoch: 39, train_loss: 0.9353, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7749, test_acc: 80.77, test_fscore: 84.38, time: 7.53 sec\n",
      "fold: 3, epoch: 40, train_loss: 0.9348, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.7901, test_acc: 77.88, test_fscore: 81.6, time: 7.53 sec\n",
      "fold: 3, epoch: 41, train_loss: 0.9341, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.8084, test_acc: 83.65, test_fscore: 87.02, time: 7.53 sec\n",
      "fold: 3, epoch: 42, train_loss: 0.933, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.8074, test_acc: 83.65, test_fscore: 87.02, time: 7.52 sec\n",
      "fold: 3, epoch: 43, train_loss: 0.9333, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.9188, test_acc: 83.65, test_fscore: 87.22, time: 7.53 sec\n",
      "fold: 3, epoch: 44, train_loss: 0.9384, train_acc: 99.76, train_fscore: 99.78, test_loss: 1.8696, test_acc: 81.73, test_fscore: 84.55, time: 7.52 sec\n",
      "fold: 3, epoch: 45, train_loss: 0.9382, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0946, test_acc: 79.81, test_fscore: 82.64, time: 7.67 sec\n",
      "fold: 3, epoch: 46, train_loss: 1.018, train_acc: 97.36, train_fscore: 97.59, test_loss: 2.2731, test_acc: 78.85, test_fscore: 84.29, time: 7.49 sec\n",
      "fold: 3, epoch: 47, train_loss: 1.011, train_acc: 97.84, train_fscore: 98.06, test_loss: 2.4674, test_acc: 74.04, test_fscore: 81.63, time: 7.49 sec\n",
      "fold: 3, epoch: 48, train_loss: 1.1667, train_acc: 94.47, train_fscore: 95.2, test_loss: 2.0378, test_acc: 78.85, test_fscore: 83.58, time: 7.52 sec\n",
      "fold: 3, epoch: 49, train_loss: 1.1492, train_acc: 93.75, train_fscore: 94.3, test_loss: 1.7822, test_acc: 76.92, test_fscore: 83.1, time: 7.6 sec\n",
      "fold: 3, epoch: 50, train_loss: 1.0263, train_acc: 98.08, train_fscore: 98.27, test_loss: 1.8159, test_acc: 80.77, test_fscore: 83.61, time: 7.52 sec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8205    0.8000    0.8101        40\n",
      "           1     0.8769    0.8906    0.8837        64\n",
      "\n",
      "    accuracy                         0.8558       104\n",
      "   macro avg     0.8487    0.8453    0.8469       104\n",
      "weighted avg     0.8552    0.8558    0.8554       104\n",
      "\n",
      "[[32  8]\n",
      " [ 7 57]]\n",
      "best model saved in:  /home/zhhaibo2023/program/msce/code/run_model/midd_runs/01-20_22-55_midd_bin_lr1e-05_dropout0.5_bs32_epochs50_fold3/saved_model/midd_model_fold3_acc.pt\n",
      "Test performance..\n",
      "fold: 3, F-Score: 88.37\n",
      "fold: 3, F-Score-index: 11\n",
      "fold: 3, Acc: 85.58\n",
      "fold: 3, Acc-index: 11\n",
      "bert_model_path: /home/zhhaibo2023/Pretrained_Model/bert-base-chinese\n",
      "Model: DepressionDetectionModel\n",
      "num_stimuls:  9\n",
      "fold: 4, epoch: 1, train_loss: 3.1633, train_acc: 57.45, train_fscore: 67.64, test_loss: 2.4718, test_acc: 44.23, test_fscore: 17.14, time: 7.97 sec\n",
      "fold: 4, epoch: 2, train_loss: 2.3155, train_acc: 56.97, train_fscore: 67.4, test_loss: 1.8447, test_acc: 61.54, test_fscore: 75.31, time: 7.68 sec\n",
      "fold: 4, epoch: 3, train_loss: 1.9299, train_acc: 63.46, train_fscore: 71.64, test_loss: 1.6416, test_acc: 73.08, test_fscore: 80.82, time: 7.71 sec\n",
      "fold: 4, epoch: 4, train_loss: 1.7516, train_acc: 68.75, train_fscore: 77.97, test_loss: 1.5616, test_acc: 68.27, test_fscore: 70.27, time: 7.57 sec\n",
      "fold: 4, epoch: 5, train_loss: 1.6075, train_acc: 81.01, train_fscore: 84.42, test_loss: 1.5057, test_acc: 71.15, test_fscore: 72.73, time: 7.62 sec\n",
      "fold: 4, epoch: 6, train_loss: 1.4843, train_acc: 84.38, train_fscore: 86.65, test_loss: 1.5367, test_acc: 69.23, test_fscore: 70.91, time: 7.59 sec\n",
      "fold: 4, epoch: 7, train_loss: 1.3842, train_acc: 87.98, train_fscore: 89.63, test_loss: 1.4487, test_acc: 74.04, test_fscore: 76.92, time: 7.6 sec\n",
      "fold: 4, epoch: 8, train_loss: 1.2991, train_acc: 91.35, train_fscore: 92.53, test_loss: 1.4627, test_acc: 77.88, test_fscore: 81.6, time: 7.63 sec\n",
      "fold: 4, epoch: 9, train_loss: 1.2315, train_acc: 93.75, train_fscore: 94.51, test_loss: 1.6722, test_acc: 70.19, test_fscore: 71.56, time: 7.58 sec\n",
      "fold: 4, epoch: 10, train_loss: 1.1649, train_acc: 96.63, train_fscore: 97.02, test_loss: 1.6221, test_acc: 72.12, test_fscore: 74.78, time: 7.6 sec\n",
      "fold: 4, epoch: 11, train_loss: 1.1055, train_acc: 97.84, train_fscore: 98.1, test_loss: 1.7113, test_acc: 72.12, test_fscore: 74.78, time: 7.76 sec\n",
      "fold: 4, epoch: 12, train_loss: 1.0716, train_acc: 98.8, train_fscore: 98.94, test_loss: 1.7609, test_acc: 74.04, test_fscore: 77.69, time: 7.55 sec\n",
      "fold: 4, epoch: 13, train_loss: 1.0965, train_acc: 96.39, train_fscore: 96.86, test_loss: 1.7978, test_acc: 74.04, test_fscore: 77.69, time: 7.55 sec\n",
      "fold: 4, epoch: 14, train_loss: 1.0585, train_acc: 98.56, train_fscore: 98.73, test_loss: 1.7797, test_acc: 75.96, test_fscore: 79.67, time: 7.64 sec\n",
      "fold: 4, epoch: 15, train_loss: 1.0533, train_acc: 98.08, train_fscore: 98.31, test_loss: 1.8427, test_acc: 73.08, test_fscore: 79.1, time: 7.5 sec\n",
      "fold: 4, epoch: 16, train_loss: 1.0581, train_acc: 98.32, train_fscore: 98.51, test_loss: 1.8547, test_acc: 76.92, test_fscore: 81.25, time: 7.48 sec\n",
      "fold: 4, epoch: 17, train_loss: 1.0289, train_acc: 98.8, train_fscore: 98.93, test_loss: 1.9203, test_acc: 72.12, test_fscore: 75.63, time: 7.44 sec\n",
      "fold: 4, epoch: 18, train_loss: 1.0061, train_acc: 99.28, train_fscore: 99.37, test_loss: 2.1434, test_acc: 71.15, test_fscore: 72.73, time: 7.6 sec\n",
      "fold: 4, epoch: 19, train_loss: 0.9931, train_acc: 99.76, train_fscore: 99.79, test_loss: 2.0434, test_acc: 72.12, test_fscore: 73.87, time: 7.67 sec\n",
      "fold: 4, epoch: 20, train_loss: 0.9808, train_acc: 99.76, train_fscore: 99.79, test_loss: 2.0757, test_acc: 71.15, test_fscore: 72.73, time: 7.61 sec\n",
      "fold: 4, epoch: 21, train_loss: 0.9733, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0064, test_acc: 73.08, test_fscore: 75.86, time: 7.61 sec\n",
      "fold: 4, epoch: 22, train_loss: 0.9707, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0896, test_acc: 72.12, test_fscore: 74.34, time: 7.6 sec\n",
      "fold: 4, epoch: 23, train_loss: 0.9656, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0273, test_acc: 70.19, test_fscore: 73.04, time: 7.65 sec\n",
      "fold: 4, epoch: 24, train_loss: 0.9629, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0505, test_acc: 70.19, test_fscore: 73.04, time: 7.71 sec\n",
      "fold: 4, epoch: 25, train_loss: 0.96, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0554, test_acc: 71.15, test_fscore: 74.14, time: 7.74 sec\n",
      "fold: 4, epoch: 26, train_loss: 0.9572, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0527, test_acc: 70.19, test_fscore: 73.5, time: 7.7 sec\n",
      "fold: 4, epoch: 27, train_loss: 0.9549, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0674, test_acc: 70.19, test_fscore: 73.5, time: 7.58 sec\n",
      "fold: 4, epoch: 28, train_loss: 0.9534, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0667, test_acc: 70.19, test_fscore: 73.5, time: 7.64 sec\n",
      "fold: 4, epoch: 29, train_loss: 0.9508, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0824, test_acc: 70.19, test_fscore: 73.5, time: 7.62 sec\n",
      "fold: 4, epoch: 30, train_loss: 0.9491, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.0956, test_acc: 70.19, test_fscore: 73.5, time: 7.63 sec\n",
      "fold: 4, epoch: 31, train_loss: 0.9481, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.124, test_acc: 71.15, test_fscore: 74.14, time: 7.69 sec\n",
      "fold: 4, epoch: 32, train_loss: 0.9461, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.1139, test_acc: 72.12, test_fscore: 75.63, time: 7.65 sec\n",
      "fold: 4, epoch: 33, train_loss: 0.9449, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.1209, test_acc: 72.12, test_fscore: 75.63, time: 7.63 sec\n",
      "fold: 4, epoch: 34, train_loss: 0.9435, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.1447, test_acc: 70.19, test_fscore: 73.5, time: 7.77 sec\n",
      "fold: 4, epoch: 35, train_loss: 0.9424, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.138, test_acc: 72.12, test_fscore: 75.63, time: 7.66 sec\n",
      "fold: 4, epoch: 36, train_loss: 0.9414, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.1691, test_acc: 70.19, test_fscore: 73.5, time: 7.63 sec\n",
      "fold: 4, epoch: 37, train_loss: 0.9399, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.1696, test_acc: 70.19, test_fscore: 73.5, time: 7.59 sec\n",
      "fold: 4, epoch: 38, train_loss: 0.9393, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.1664, test_acc: 73.08, test_fscore: 76.67, time: 7.67 sec\n",
      "fold: 4, epoch: 39, train_loss: 0.9383, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.1743, test_acc: 72.12, test_fscore: 75.63, time: 7.67 sec\n",
      "fold: 4, epoch: 40, train_loss: 0.9374, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.1789, test_acc: 73.08, test_fscore: 76.67, time: 7.62 sec\n",
      "fold: 4, epoch: 41, train_loss: 0.9364, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.1882, test_acc: 73.08, test_fscore: 76.67, time: 7.75 sec\n",
      "fold: 4, epoch: 42, train_loss: 0.9357, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.1888, test_acc: 73.08, test_fscore: 76.67, time: 7.66 sec\n",
      "fold: 4, epoch: 43, train_loss: 0.9352, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.2139, test_acc: 73.08, test_fscore: 76.67, time: 7.65 sec\n",
      "fold: 4, epoch: 44, train_loss: 0.9343, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.2223, test_acc: 73.08, test_fscore: 76.67, time: 7.7 sec\n",
      "fold: 4, epoch: 45, train_loss: 0.9337, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.2499, test_acc: 73.08, test_fscore: 76.67, time: 7.65 sec\n",
      "fold: 4, epoch: 46, train_loss: 0.9331, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.2773, test_acc: 70.19, test_fscore: 73.5, time: 7.62 sec\n",
      "fold: 4, epoch: 47, train_loss: 0.9325, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.2696, test_acc: 74.04, test_fscore: 77.69, time: 7.63 sec\n",
      "fold: 4, epoch: 48, train_loss: 0.9317, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.2882, test_acc: 71.15, test_fscore: 74.58, time: 7.66 sec\n",
      "fold: 4, epoch: 49, train_loss: 0.9314, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.3055, test_acc: 74.04, test_fscore: 77.69, time: 7.72 sec\n",
      "fold: 4, epoch: 50, train_loss: 0.9307, train_acc: 100.0, train_fscore: 100.0, test_loss: 2.3013, test_acc: 72.12, test_fscore: 75.63, time: 7.94 sec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.6977    0.7229        43\n",
      "           1     0.7969    0.8361    0.8160        61\n",
      "\n",
      "    accuracy                         0.7788       104\n",
      "   macro avg     0.7734    0.7669    0.7694       104\n",
      "weighted avg     0.7775    0.7788    0.7775       104\n",
      "\n",
      "[[30 13]\n",
      " [10 51]]\n",
      "best model saved in:  /home/zhhaibo2023/program/msce/code/run_model/midd_runs/01-20_23-02_midd_bin_lr1e-05_dropout0.5_bs32_epochs50_fold4/saved_model/midd_model_fold4_acc.pt\n",
      "Test performance..\n",
      "fold: 4, F-Score: 81.6\n",
      "fold: 4, F-Score-index: 8\n",
      "fold: 4, Acc: 77.88\n",
      "fold: 4, Acc-index: 8\n",
      "bert_model_path: /home/zhhaibo2023/Pretrained_Model/bert-base-chinese\n",
      "Model: DepressionDetectionModel\n",
      "num_stimuls:  9\n",
      "fold: 5, epoch: 1, train_loss: 3.2541, train_acc: 57.45, train_fscore: 70.45, test_loss: 2.5155, test_acc: 52.88, test_fscore: 69.18, time: 8.05 sec\n",
      "fold: 5, epoch: 2, train_loss: 2.3768, train_acc: 60.82, train_fscore: 73.58, test_loss: 1.9438, test_acc: 74.04, test_fscore: 70.33, time: 7.86 sec\n",
      "fold: 5, epoch: 3, train_loss: 1.946, train_acc: 61.54, train_fscore: 74.28, test_loss: 1.6743, test_acc: 79.81, test_fscore: 79.21, time: 7.84 sec\n",
      "fold: 5, epoch: 4, train_loss: 1.7678, train_acc: 68.75, train_fscore: 75.56, test_loss: 1.487, test_acc: 75.96, test_fscore: 80.92, time: 7.64 sec\n",
      "fold: 5, epoch: 5, train_loss: 1.6364, train_acc: 76.2, train_fscore: 81.14, test_loss: 1.3346, test_acc: 86.54, test_fscore: 88.14, time: 7.81 sec\n",
      "fold: 5, epoch: 6, train_loss: 1.5179, train_acc: 83.17, train_fscore: 86.22, test_loss: 1.2365, test_acc: 88.46, test_fscore: 89.66, time: 7.81 sec\n",
      "fold: 5, epoch: 7, train_loss: 1.4169, train_acc: 87.26, train_fscore: 89.42, test_loss: 1.2511, test_acc: 86.54, test_fscore: 88.33, time: 7.77 sec\n",
      "fold: 5, epoch: 8, train_loss: 1.3755, train_acc: 87.98, train_fscore: 90.0, test_loss: 1.2325, test_acc: 88.46, test_fscore: 89.83, time: 7.8 sec\n",
      "fold: 5, epoch: 9, train_loss: 1.3294, train_acc: 89.18, train_fscore: 90.95, test_loss: 1.2477, test_acc: 87.5, test_fscore: 89.08, time: 7.78 sec\n",
      "fold: 5, epoch: 10, train_loss: 1.2524, train_acc: 91.83, train_fscore: 93.15, test_loss: 1.2155, test_acc: 87.5, test_fscore: 89.08, time: 7.61 sec\n",
      "fold: 5, epoch: 11, train_loss: 1.1896, train_acc: 95.19, train_fscore: 95.9, test_loss: 1.1672, test_acc: 91.35, test_fscore: 92.04, time: 8.1 sec\n",
      "fold: 5, epoch: 12, train_loss: 1.1222, train_acc: 96.63, train_fscore: 97.14, test_loss: 1.1939, test_acc: 86.54, test_fscore: 88.14, time: 7.69 sec\n",
      "fold: 5, epoch: 13, train_loss: 1.0772, train_acc: 98.56, train_fscore: 98.77, test_loss: 1.2293, test_acc: 87.5, test_fscore: 89.08, time: 7.79 sec\n",
      "fold: 5, epoch: 14, train_loss: 1.0497, train_acc: 99.04, train_fscore: 99.18, test_loss: 1.2178, test_acc: 86.54, test_fscore: 88.14, time: 7.71 sec\n",
      "fold: 5, epoch: 15, train_loss: 1.0365, train_acc: 99.04, train_fscore: 99.17, test_loss: 1.2183, test_acc: 86.54, test_fscore: 87.27, time: 7.66 sec\n",
      "fold: 5, epoch: 16, train_loss: 1.0309, train_acc: 98.08, train_fscore: 98.33, test_loss: 1.3338, test_acc: 82.69, test_fscore: 82.0, time: 7.68 sec\n",
      "fold: 5, epoch: 17, train_loss: 1.005, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.1827, test_acc: 92.31, test_fscore: 92.98, time: 7.83 sec\n",
      "fold: 5, epoch: 18, train_loss: 0.9943, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.1707, test_acc: 90.38, test_fscore: 91.07, time: 7.66 sec\n",
      "fold: 5, epoch: 19, train_loss: 0.9913, train_acc: 99.76, train_fscore: 99.79, test_loss: 1.2783, test_acc: 84.62, test_fscore: 84.31, time: 7.86 sec\n",
      "fold: 5, epoch: 20, train_loss: 0.982, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2808, test_acc: 88.46, test_fscore: 89.66, time: 7.78 sec\n",
      "fold: 5, epoch: 21, train_loss: 0.9743, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2263, test_acc: 85.58, test_fscore: 85.98, time: 7.85 sec\n",
      "fold: 5, epoch: 22, train_loss: 0.9705, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2458, test_acc: 89.42, test_fscore: 90.43, time: 7.71 sec\n",
      "fold: 5, epoch: 23, train_loss: 0.966, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2306, test_acc: 89.42, test_fscore: 90.09, time: 7.61 sec\n",
      "fold: 5, epoch: 24, train_loss: 0.9635, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2384, test_acc: 88.46, test_fscore: 89.09, time: 7.62 sec\n",
      "fold: 5, epoch: 25, train_loss: 0.9597, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2418, test_acc: 90.38, test_fscore: 91.07, time: 7.62 sec\n",
      "fold: 5, epoch: 26, train_loss: 0.9574, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2448, test_acc: 89.42, test_fscore: 90.09, time: 7.63 sec\n",
      "fold: 5, epoch: 27, train_loss: 0.9551, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2451, test_acc: 87.5, test_fscore: 88.07, time: 7.74 sec\n",
      "fold: 5, epoch: 28, train_loss: 0.954, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.263, test_acc: 90.38, test_fscore: 91.23, time: 7.77 sec\n",
      "fold: 5, epoch: 29, train_loss: 0.9512, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2432, test_acc: 89.42, test_fscore: 90.27, time: 7.59 sec\n",
      "fold: 5, epoch: 30, train_loss: 0.9496, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2498, test_acc: 87.5, test_fscore: 88.29, time: 7.72 sec\n",
      "fold: 5, epoch: 31, train_loss: 0.9478, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2531, test_acc: 90.38, test_fscore: 91.23, time: 7.81 sec\n",
      "fold: 5, epoch: 32, train_loss: 0.9464, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2512, test_acc: 87.5, test_fscore: 88.07, time: 7.74 sec\n",
      "fold: 5, epoch: 33, train_loss: 0.9449, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2456, test_acc: 88.46, test_fscore: 89.09, time: 7.69 sec\n",
      "fold: 5, epoch: 34, train_loss: 0.9438, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2473, test_acc: 87.5, test_fscore: 88.07, time: 7.7 sec\n",
      "fold: 5, epoch: 35, train_loss: 0.9423, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.257, test_acc: 88.46, test_fscore: 89.09, time: 7.72 sec\n",
      "fold: 5, epoch: 36, train_loss: 0.9411, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2569, test_acc: 88.46, test_fscore: 89.09, time: 7.7 sec\n",
      "fold: 5, epoch: 37, train_loss: 0.9399, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2614, test_acc: 88.46, test_fscore: 89.09, time: 7.64 sec\n",
      "fold: 5, epoch: 38, train_loss: 0.9394, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2687, test_acc: 91.35, test_fscore: 92.04, time: 7.68 sec\n",
      "fold: 5, epoch: 39, train_loss: 0.9384, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2738, test_acc: 87.5, test_fscore: 88.07, time: 7.74 sec\n",
      "fold: 5, epoch: 40, train_loss: 0.9373, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.268, test_acc: 90.38, test_fscore: 91.23, time: 7.72 sec\n",
      "fold: 5, epoch: 41, train_loss: 0.9368, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2756, test_acc: 90.38, test_fscore: 91.23, time: 7.86 sec\n",
      "fold: 5, epoch: 42, train_loss: 0.9358, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2719, test_acc: 88.46, test_fscore: 88.89, time: 7.68 sec\n",
      "fold: 5, epoch: 43, train_loss: 0.935, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2695, test_acc: 88.46, test_fscore: 89.09, time: 7.8 sec\n",
      "fold: 5, epoch: 44, train_loss: 0.9342, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2663, test_acc: 89.42, test_fscore: 89.91, time: 7.78 sec\n",
      "fold: 5, epoch: 45, train_loss: 0.9339, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2863, test_acc: 88.46, test_fscore: 88.89, time: 7.71 sec\n",
      "fold: 5, epoch: 46, train_loss: 0.9334, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2629, test_acc: 91.35, test_fscore: 92.04, time: 7.59 sec\n",
      "fold: 5, epoch: 47, train_loss: 0.9328, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2633, test_acc: 90.38, test_fscore: 90.91, time: 7.83 sec\n",
      "fold: 5, epoch: 48, train_loss: 0.932, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2823, test_acc: 90.38, test_fscore: 91.23, time: 7.66 sec\n",
      "fold: 5, epoch: 49, train_loss: 0.9314, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.3119, test_acc: 87.5, test_fscore: 87.85, time: 7.75 sec\n",
      "fold: 5, epoch: 50, train_loss: 0.9307, train_acc: 100.0, train_fscore: 100.0, test_loss: 1.2833, test_acc: 89.42, test_fscore: 89.91, time: 7.57 sec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9556    0.8776    0.9149        49\n",
      "           1     0.8983    0.9636    0.9298        55\n",
      "\n",
      "    accuracy                         0.9231       104\n",
      "   macro avg     0.9269    0.9206    0.9224       104\n",
      "weighted avg     0.9253    0.9231    0.9228       104\n",
      "\n",
      "[[43  6]\n",
      " [ 2 53]]\n",
      "best model saved in:  /home/zhhaibo2023/program/msce/code/run_model/midd_runs/01-20_23-08_midd_bin_lr1e-05_dropout0.5_bs32_epochs50_fold5/saved_model/midd_model_fold5_acc.pt\n",
      "Test performance..\n",
      "fold: 5, F-Score: 92.98\n",
      "fold: 5, F-Score-index: 17\n",
      "fold: 5, Acc: 92.31\n",
      "fold: 5, Acc-index: 17\n",
      "5-fold ave fscore: 87.614\n",
      "5-fold ave acc: 85.38399999999999\n"
     ]
    }
   ],
   "source": [
    "test_label_list_perfold, test_pred_list_perfold, test_id_list_perfold, best_test_acc, best_test_fs = run(dataset=dataset,\n",
    "                                                                                                        dataset_name=dataset_name,\n",
    "                                                                                                        logdir_root=logdir_root,\n",
    "                                                                                                        classify_flag=classify_flag,\n",
    "                                                                                                        device=device,\n",
    "                                                                                                        gammas=gammas,\n",
    "                                                                                                        SEED=SEED,\n",
    "                                                                                                        BS=BS,\n",
    "                                                                                                        LR=LR,\n",
    "                                                                                                        Weight_Decay=Weight_Decay,\n",
    "                                                                                                        Dropout=Dropout,\n",
    "                                                                                                        EPOCHS=EPOCHS,\n",
    "                                                                                                        K=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.1.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
